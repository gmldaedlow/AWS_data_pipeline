{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdea952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import dotenv\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import date\n",
    "import datetime\n",
    "import sqlalchemy # install if needed\n",
    "import pymysql\n",
    "import dotenv\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43794b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BER': 'Berlin', 'BCN': 'Barcelona', 'STR': 'Stuttgart', 'LPZ': 'Leipzig'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here, I manually define the cities of interest with a unique key. I can also call them from mySQL\n",
    "cities = {\"BER\":\"Berlin\", \"BCN\":\"Barcelona\", \"STR\":\"Stuttgart\", \"LPZ\":\"Leipzig\"}\n",
    "\n",
    "#sql_query = pd.read_sql('SELECT city_id, city FROM city', con)\n",
    "#cities = dict(zip(sql_query.city_id, sql_query.city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "542f3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City Wiki Function\n",
    "\n",
    "def scrap_wiki(cities):\n",
    "\n",
    "    city = []\n",
    "    city_id = []\n",
    "    country = []\n",
    "    population = []\n",
    "    lat = []\n",
    "    lon = []\n",
    "    today = []\n",
    "    \n",
    "    schema=\"schema\"\n",
    "    host=\"AWS_host\"\n",
    "    dotenv.load_dotenv() # the api key is in a .env file in the same directory\n",
    "    password = os.getenv('sql_password')\n",
    "    user=\"admin\"\n",
    "    port=3306\n",
    "    con = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "    \n",
    "\n",
    "    for key, c in cities.items():\n",
    "        url = f\"https://en.wikipedia.org/wiki/{c}\"\n",
    "        # 3. download html with a get request\n",
    "        headers = {'Accept-Language': 'en-US,en;q=0.8'}\n",
    "        response = requests.get(url, headers = headers)\n",
    "        print(c, response.status_code) # 200 status code means OK! check\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        city.append(c)\n",
    "        country.append(soup.select(\"td.infobox-data\")[0].get_text())\n",
    "        if soup.select(\"th.infobox-header:-soup-contains('Population')\"):\n",
    "            population.append(soup.select(\"th.infobox-header:-soup-contains('Population')\")[0].parent.find_next_sibling().contents[1].get_text())\n",
    "        lat.append(soup.select(\".latitude\")[0].get_text())\n",
    "        lon.append(soup.select(\".longitude\")[0].get_text())\n",
    "        today.append(date.today())\n",
    "        city_id.append(key)\n",
    "        # elevation = \n",
    "    wiki_df = pd.DataFrame({\"city_id\":city_id,\n",
    "                \"city\":city, \n",
    "                 \"country\":country,\n",
    "                \"population\":population,\n",
    "                 \"lat\":lat, \n",
    "                 \"lon\":lon,\n",
    "                    \"timestamp\": today,\n",
    "                    \"city_id\":city_id})\n",
    "    wiki_df[\"lat\"] = wiki_df[\"lat\"].str.split('″').str[0].str.replace('°', '.', regex=False).str.replace('′', '', regex=False)\n",
    "    wiki_df[\"lon\"] = wiki_df[\"lon\"].str.split('″').str[0].str.replace('°', '.', regex=False).str.replace('′', '', regex=False)\n",
    "    wiki_df[\"population\"] = wiki_df[\"population\"].str.replace(',', '', regex=False)\n",
    "    # saving it as a csv\n",
    "    #wiki_df.to_csv(\"city_wiki.csv\", index=False)\n",
    "    wiki_df.to_sql('city', \n",
    "              if_exists='append', \n",
    "              con=con, \n",
    "              index=False)\n",
    "    return(wiki_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "229d428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin 200\n",
      "Barcelona 200\n",
      "Stuttgart 200\n",
      "Leipzig 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BER</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "      <td>3850809</td>\n",
       "      <td>52.3112</td>\n",
       "      <td>13.2418</td>\n",
       "      <td>2023-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCN</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1620343</td>\n",
       "      <td>41.2258</td>\n",
       "      <td>02.1037</td>\n",
       "      <td>2023-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STR</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>Germany</td>\n",
       "      <td>626275</td>\n",
       "      <td>48.4639</td>\n",
       "      <td>09.1048</td>\n",
       "      <td>2023-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LPZ</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Germany</td>\n",
       "      <td>601866</td>\n",
       "      <td>51.2024</td>\n",
       "      <td>12.2230</td>\n",
       "      <td>2023-08-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_id       city  country population      lat      lon   timestamp\n",
       "0     BER     Berlin  Germany    3850809  52.3112  13.2418  2023-08-02\n",
       "1     BCN  Barcelona    Spain    1620343  41.2258  02.1037  2023-08-02\n",
       "2     STR  Stuttgart  Germany     626275  48.4639  09.1048  2023-08-02\n",
       "3     LPZ    Leipzig  Germany     601866  51.2024  12.2230  2023-08-02"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = scrap_wiki(cities)\n",
    "wiki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d3a6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICAO Function  \n",
    "def airports_per_city(wiki_df):\n",
    "    \n",
    "    schema=\"schema\"\n",
    "    host=\"AWS_host\"\n",
    "    dotenv.load_dotenv() # the api key is in a .env file in the same directory\n",
    "    password = os.getenv('sql_password')\n",
    "    user=\"admin\"\n",
    "    port=3306\n",
    "    con = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "    \n",
    "\n",
    "    lat = wiki_df[\"lat\"]\n",
    "    long = wiki_df[\"lon\"]\n",
    "    city_id = wiki_df[\"city_id\"]\n",
    "    list = []\n",
    "    airport_df = []\n",
    "\n",
    "    for lat, long, city_id in zip(lat, long, city_id):\n",
    "\n",
    "        url = \"https://aerodatabox.p.rapidapi.com/airports/search/location\"\n",
    "    \n",
    "        querystring = {\"lat\":lat,\"lon\":long,\"radiusKm\":\"100\",\"limit\":\"10\"}\n",
    "\n",
    "        headers = {\n",
    "        \"X-RapidAPI-Key\": \"0b7cffd425mshbf932b1b5f7e633p187a96jsna5aedb4ce276\",\n",
    "        \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "            }\n",
    "    \n",
    "        response = requests.get(url, headers=headers, params=querystring)\n",
    "        print(city_id, response)\n",
    "        df = pd.DataFrame(pd.json_normalize(response.json()['items']))\n",
    "        df[\"city_id\"] = city_id\n",
    "        list.append(df)\n",
    "    airport_df = pd.concat(list)\n",
    "    airport_df = airport_df[[\"city_id\", \"icao\", \"name\", \"countryCode\", \"location.lat\", \"location.lon\"]]\n",
    "    airport_df.rename(columns={\"countryCode\":\"country_code\", \"location.lat\":\"lat\", \"location.lon\":\"lon\"}, inplace=True)\n",
    "    airport_df.to_sql('airport', \n",
    "              if_exists='append', \n",
    "              con=con, \n",
    "              index=False)  \n",
    "    return (airport_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335cb5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER <Response [200]>\n",
      "BCN <Response [200]>\n",
      "STR <Response [200]>\n",
      "LPZ <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "airport_df = airports_per_city(wiki_df)\n",
    "airport_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
